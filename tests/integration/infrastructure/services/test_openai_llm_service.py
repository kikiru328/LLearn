import pytest
from unittest.mock import Mock, AsyncMock, patch

from infrastructure.services.openai_llm_service import OpenAILLMService


class TestOpenAILLMService:
    @pytest.fixture
    def llm_service(self):
        return OpenAILLMService(api_key="test-api-key", model="gpt-4o")
    
    @pytest.mark.asyncio
    @patch('openai.AsyncOpenAI')
    async def test_generate_feedback_calls_openai_correctly(self, mock_openai_client, llm_service):
        # Given
        mock_client_instance = Mock()
        mock_openai_client.return_value = mock_client_instance
        
        mock_response = Mock()
        mock_response.choices = [Mock()]
        mock_response.choices[0].message.content = """
        1. âœ… ì •í™•ì„± í™•ì¸: í”„ë¡œì„¸ìŠ¤ì˜ ë…ë¦½ì„±ì— ëŒ€í•´ ì˜ ì´í•´í•˜ì…¨ìŠµë‹ˆë‹¤
        2. ğŸ“ ëˆ„ë½ ë³´ì¶©: ìŠ¤ë ˆë“œì™€ì˜ ì°¨ì´ì ì„ ì¶”ê°€ë¡œ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤
        3. âš ï¸ ì˜¤ë¥˜ ìˆ˜ì •: íŠ¹ë³„í•œ ì˜¤ë¥˜ëŠ” ì—†ìŠµë‹ˆë‹¤
        4. ğŸ¤” ì‹¬í™” ì§ˆë¬¸: ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­ ë¹„ìš©ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?
        5. ğŸ“š í™•ì¥ í•™ìŠµ: IPC ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•´ í•™ìŠµí•´ë³´ì„¸ìš”
        """
        
        mock_client_instance.chat.completions.create = AsyncMock(return_value=mock_response)
        
        # ì‹¤ì œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì¬ìƒì„± (mockì´ ì ìš©ë˜ë„ë¡)
        service = OpenAILLMService(api_key="test-api-key")
        
        # When
        result = await service.generate_feedback(
            summary_content="í”„ë¡œì„¸ìŠ¤ëŠ” ë…ë¦½ì ì¸ ë©”ëª¨ë¦¬ ê³µê°„ì„ ê°€ì§‘ë‹ˆë‹¤",
            week_topic_title="ìš´ì˜ì²´ì œ ê¸°ì´ˆ",
            week_topic_description="í”„ë¡œì„¸ìŠ¤ì™€ ìŠ¤ë ˆë“œ ê°œë… í•™ìŠµ",
            learning_goals=["í”„ë¡œì„¸ìŠ¤ ì´í•´", "ìŠ¤ë ˆë“œ ì´í•´"]
        )
        
        # Then
        assert "ì •í™•ì„± í™•ì¸" in result
        assert "ëˆ„ë½ ë³´ì¶©" in result
        assert "ì˜¤ë¥˜ ìˆ˜ì •" in result
        assert "ì‹¬í™” ì§ˆë¬¸" in result
        assert "í™•ì¥ í•™ìŠµ" in result
        
        # OpenAI API í˜¸ì¶œ í™•ì¸
        mock_client_instance.chat.completions.create.assert_called_once()
        call_args = mock_client_instance.chat.completions.create.call_args
        
        assert call_args.kwargs['model'] == "gpt-4o"
        assert len(call_args.kwargs['messages']) == 2
        assert "ì „ë¬¸ì ì¸ CS êµìœ¡ ë©˜í† " in call_args.kwargs['messages'][0]['content']
        assert "ìš´ì˜ì²´ì œ ê¸°ì´ˆ" in call_args.kwargs['messages'][1]['content']
    
    def test_build_feedback_prompt_includes_all_context(self, llm_service):
        # Given
        summary_content = "í”„ë¡œì„¸ìŠ¤ëŠ” ë…ë¦½ì ì…ë‹ˆë‹¤"
        week_topic_title = "ìš´ì˜ì²´ì œ"
        week_topic_description = "í”„ë¡œì„¸ìŠ¤ ê°œë…"
        learning_goals = ["í”„ë¡œì„¸ìŠ¤ ì´í•´", "ìŠ¤ë ˆë“œ ì´í•´"]
        
        # When
        prompt = llm_service._build_feedback_prompt(
            summary_content, week_topic_title, week_topic_description, learning_goals
        )
        
        # Then
        assert "ìš´ì˜ì²´ì œ" in prompt
        assert "í”„ë¡œì„¸ìŠ¤ ê°œë…" in prompt
        assert "í”„ë¡œì„¸ìŠ¤ ì´í•´, ìŠ¤ë ˆë“œ ì´í•´" in prompt
        assert "í”„ë¡œì„¸ìŠ¤ëŠ” ë…ë¦½ì ì…ë‹ˆë‹¤" in prompt
        assert "âœ… ì •í™•ì„± í™•ì¸" in prompt
        assert "ğŸ“ ëˆ„ë½ ë³´ì¶©" in prompt
        assert "âš ï¸ ì˜¤ë¥˜ ìˆ˜ì •" in prompt
        assert "ğŸ¤” ì‹¬í™” ì§ˆë¬¸" in prompt
        assert "ğŸ“š í™•ì¥ í•™ìŠµ" in prompt